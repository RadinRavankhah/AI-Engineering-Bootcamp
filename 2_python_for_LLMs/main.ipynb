{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "086d7e7c",
   "metadata": {},
   "source": [
    "### üßë‚Äçüè´ Practical Lesson: Python for LLMs (Step 1 after OOP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e1ab37",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38c6840",
   "metadata": {},
   "source": [
    "#### 1. Strings & Tokenization\n",
    "\n",
    "üìå LLMs work with tokens (sub-pieces of text). Before huggingface/transformers, show them basic text processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a3138e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"ChatGPT is amazing at Python!\"\n",
    "\n",
    "# Simple tokenization (split by spaces)\n",
    "tokens = text.split()\n",
    "print(\"Tokens:\", tokens)\n",
    "\n",
    "# Lowercasing\n",
    "tokens = [t.lower() for t in tokens]\n",
    "print(\"Lowercased:\", tokens)\n",
    "\n",
    "# Count tokens\n",
    "print(\"Number of tokens:\", len(tokens))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc66f39",
   "metadata": {},
   "source": [
    "üëâ Teaching point: LLM tokenizers are more advanced, but conceptually similar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61a31bd",
   "metadata": {},
   "source": [
    "--- "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c9a8fa",
   "metadata": {},
   "source": [
    "#### 2. Word Embeddings (Manual)\n",
    "\n",
    "üìå Show how words can be represented as vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2826b161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Fake word embeddings (in real LLMs these are learned)\n",
    "embeddings = {\n",
    "    \"cat\": np.array([1, 0, 0]),\n",
    "    \"dog\": np.array([0.9, 0.1, 0]),\n",
    "    \"apple\": np.array([0, 1, 0])\n",
    "}\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))\n",
    "\n",
    "print(\"cat vs dog:\", cosine_similarity(embeddings[\"cat\"], embeddings[\"dog\"]))\n",
    "print(\"cat vs apple:\", cosine_similarity(embeddings[\"cat\"], embeddings[\"apple\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b17e71",
   "metadata": {},
   "source": [
    "üëâ Teaching point: This shows why ‚Äúcat‚Äù and ‚Äúdog‚Äù are closer in meaning than ‚Äúcat‚Äù and ‚Äúapple.‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092fa48e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294b8449",
   "metadata": {},
   "source": [
    "#### 3. Using a Real Tokenizer (Hugging Face)\n",
    "\n",
    "üìå Transition to actual tools used in LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7556a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "text = \"Large Language Models are powerful.\"\n",
    "tokens = tokenizer.tokenize(text)\n",
    "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "print(\"Tokens:\", tokens)\n",
    "print(\"Token IDs:\", ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dfa478",
   "metadata": {},
   "source": [
    "üëâ Teaching point: Show them subword tokenization (\"powerful\" ‚Üí \"power\", \"##ful\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b945bee",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a1db45",
   "metadata": {},
   "source": [
    "#### 4. Using a Small LLM for Inference\n",
    "\n",
    "üìå First taste of running a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f7c049",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "generator = pipeline(\"text-generation\", model=\"distilgpt2\")\n",
    "\n",
    "result = generator(\"Artificial intelligence is\", max_length=20, num_return_sequences=1)\n",
    "print(result[0][\"generated_text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e113b45",
   "metadata": {},
   "source": [
    "üëâ Teaching point: They see how LLMs actually produce text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e6ca74",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d375e257",
   "metadata": {},
   "source": [
    "#### 5. Mini-Project: Build a Q&A Assistant\n",
    "\n",
    "üìå Show retrieval + LLM answering (very simplified)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27a18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
    "\n",
    "context = \"\"\"\n",
    "Python is a programming language created by Guido van Rossum.\n",
    "It is widely used in AI, machine learning, and data science.\n",
    "\"\"\"\n",
    "\n",
    "question = \"Who created Python?\"\n",
    "answer = qa_pipeline(question=question, context=context)\n",
    "\n",
    "print(\"Answer:\", answer[\"answer\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e0238d",
   "metadata": {},
   "source": [
    "üëâ Teaching point: This connects text processing ‚Üí embeddings ‚Üí LLMs ‚Üí actual AI use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b838aa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c93d1e",
   "metadata": {},
   "source": [
    "#### 6. Exercises for Students\n",
    "\n",
    "Tokenize their own text using Hugging Face tokenizer.\n",
    "\n",
    "Compare cosine similarity between words they choose.\n",
    "\n",
    "Try changing the prompt for distilgpt2 and see what it generates.\n",
    "\n",
    "Create their own mini knowledge base (a few sentences of context) and ask it questions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
